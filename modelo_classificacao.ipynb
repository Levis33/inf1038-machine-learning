{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Classifica√ß√£o (Youtube Video Dataset)\n",
    "https://www.kaggle.com/datasets/rahulanand0070/youtubevideodataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# NLTK\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# SKLearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepara√ß√£o do Dataset\n",
    "\n",
    "A partir do .csv informado, vamos preparar o dataset para os algoritmos. Nesse caso, vamos remover valores nulos e filtrar as colunas de interesse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Videourl</th>\n",
       "      <th>Category</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Madagascar Street Food!!! Super RARE Malagasy ...</td>\n",
       "      <td>/watch?v=EwBA1fOQ96c</td>\n",
       "      <td>Food</td>\n",
       "      <td>üé•GIANT ALIEN SNAIL IN JAPAN! ¬ª https://youtu.b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42 Foods You Need To Eat Before You Die</td>\n",
       "      <td>/watch?v=0SPwwpruGIA</td>\n",
       "      <td>Food</td>\n",
       "      <td>This is the ultimate must-try food bucket list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gordon Ramsay‚Äôs Top 5 Indian Dishes</td>\n",
       "      <td>/watch?v=upfu5nQB2ks</td>\n",
       "      <td>Food</td>\n",
       "      <td>We found 5 of the best and most interesting In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How To Use Chopsticks - In About A Minute üçú</td>\n",
       "      <td>/watch?v=xFRzzSF_6gk</td>\n",
       "      <td>Food</td>\n",
       "      <td>You're most likely sitting in a restaurant wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying Indian Food 1st Time!</td>\n",
       "      <td>/watch?v=K79bXtaRwcM</td>\n",
       "      <td>Food</td>\n",
       "      <td>HELP SUPPORT SINSTV!! Shop Our Sponsors!\\nLast...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title              Videourl  \\\n",
       "0  Madagascar Street Food!!! Super RARE Malagasy ...  /watch?v=EwBA1fOQ96c   \n",
       "1            42 Foods You Need To Eat Before You Die  /watch?v=0SPwwpruGIA   \n",
       "2                Gordon Ramsay‚Äôs Top 5 Indian Dishes  /watch?v=upfu5nQB2ks   \n",
       "3        How To Use Chopsticks - In About A Minute üçú  /watch?v=xFRzzSF_6gk   \n",
       "4                       Trying Indian Food 1st Time!  /watch?v=K79bXtaRwcM   \n",
       "\n",
       "  Category                                        Description  \n",
       "0     Food  üé•GIANT ALIEN SNAIL IN JAPAN! ¬ª https://youtu.b...  \n",
       "1     Food  This is the ultimate must-try food bucket list...  \n",
       "2     Food  We found 5 of the best and most interesting In...  \n",
       "3     Food  You're most likely sitting in a restaurant wit...  \n",
       "4     Food  HELP SUPPORT SINSTV!! Shop Our Sponsors!\\nLast...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/youtube_video_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas: Title Videourl Category Description\n",
      "N√∫mero de Linhas: 11211\n",
      "Colunas: Title Category Description\n",
      "N√∫mero de Linhas com Valores Nulos: 83\n",
      "N√∫mero de Linhas Ap√≥s Remo√ß√£o de Nulos: 11128\n",
      "N√∫mero de Linhas com Valores Nulos (Verifica√ß√£o): 0\n"
     ]
    }
   ],
   "source": [
    "colunas = list()\n",
    "for coluna in df.columns:\n",
    "    colunas.append(coluna)\n",
    "print(\"Colunas:\", \" \".join(colunas))\n",
    "print(\"N√∫mero de Linhas:\", df.shape[0])\n",
    "# Removendo as colunas que n√£o s√£o interessantes (nesse caso, apenas importa \"Title\" e \"Category\")\n",
    "df = df.iloc[:, [0, 2, 3]]\n",
    "colunas = list()\n",
    "for coluna in df.columns:\n",
    "    colunas.append(coluna)\n",
    "print(\"Colunas:\", \" \".join(colunas))\n",
    "print(\"N√∫mero de Linhas com Valores Nulos:\", df.isna().sum().sum())\n",
    "# Retirando linhas com valores nulos \n",
    "df = df.dropna()\n",
    "print(\"N√∫mero de Linhas Ap√≥s Remo√ß√£o de Nulos:\", df.shape[0])\n",
    "print(\"N√∫mero de Linhas com Valores Nulos (Verifica√ß√£o):\", df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novo dataset com as colunas novas e valores removidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Madagascar Street Food!!! Super RARE Malagasy ...</td>\n",
       "      <td>Food</td>\n",
       "      <td>üé•GIANT ALIEN SNAIL IN JAPAN! ¬ª https://youtu.b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42 Foods You Need To Eat Before You Die</td>\n",
       "      <td>Food</td>\n",
       "      <td>This is the ultimate must-try food bucket list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gordon Ramsay‚Äôs Top 5 Indian Dishes</td>\n",
       "      <td>Food</td>\n",
       "      <td>We found 5 of the best and most interesting In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How To Use Chopsticks - In About A Minute üçú</td>\n",
       "      <td>Food</td>\n",
       "      <td>You're most likely sitting in a restaurant wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying Indian Food 1st Time!</td>\n",
       "      <td>Food</td>\n",
       "      <td>HELP SUPPORT SINSTV!! Shop Our Sponsors!\\nLast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11206</th>\n",
       "      <td>art journal | shimmer sprays, stencils, collag...</td>\n",
       "      <td>Art&amp;Music</td>\n",
       "      <td>Step by step video on creating an art journal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11207</th>\n",
       "      <td>Ar-Tea Collage * Mixed Media Art</td>\n",
       "      <td>Art&amp;Music</td>\n",
       "      <td>By: Ilene McInnes,\\nMixed media Art and inspir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11208</th>\n",
       "      <td>DIY Mixed Media Art Collage Greeting Cards / M...</td>\n",
       "      <td>Art&amp;Music</td>\n",
       "      <td>Make your own Mixed Media Greeting Cards\\n\\nHe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11209</th>\n",
       "      <td>Art Collage Process DecoJournal using Rice Pap...</td>\n",
       "      <td>Art&amp;Music</td>\n",
       "      <td>Art Collage Process DecoJournal using Rice Pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11210</th>\n",
       "      <td>Journal Collage Process using Magazine Cut Out...</td>\n",
       "      <td>Art&amp;Music</td>\n",
       "      <td>Using magazine, scrapbook paper, recycled old ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11128 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title   Category  \\\n",
       "0      Madagascar Street Food!!! Super RARE Malagasy ...       Food   \n",
       "1                42 Foods You Need To Eat Before You Die       Food   \n",
       "2                    Gordon Ramsay‚Äôs Top 5 Indian Dishes       Food   \n",
       "3            How To Use Chopsticks - In About A Minute üçú       Food   \n",
       "4                           Trying Indian Food 1st Time!       Food   \n",
       "...                                                  ...        ...   \n",
       "11206  art journal | shimmer sprays, stencils, collag...  Art&Music   \n",
       "11207                   Ar-Tea Collage * Mixed Media Art  Art&Music   \n",
       "11208  DIY Mixed Media Art Collage Greeting Cards / M...  Art&Music   \n",
       "11209  Art Collage Process DecoJournal using Rice Pap...  Art&Music   \n",
       "11210  Journal Collage Process using Magazine Cut Out...  Art&Music   \n",
       "\n",
       "                                             Description  \n",
       "0      üé•GIANT ALIEN SNAIL IN JAPAN! ¬ª https://youtu.b...  \n",
       "1      This is the ultimate must-try food bucket list...  \n",
       "2      We found 5 of the best and most interesting In...  \n",
       "3      You're most likely sitting in a restaurant wit...  \n",
       "4      HELP SUPPORT SINSTV!! Shop Our Sponsors!\\nLast...  \n",
       "...                                                  ...  \n",
       "11206  Step by step video on creating an art journal ...  \n",
       "11207  By: Ilene McInnes,\\nMixed media Art and inspir...  \n",
       "11208  Make your own Mixed Media Greeting Cards\\n\\nHe...  \n",
       "11209  Art Collage Process DecoJournal using Rice Pap...  \n",
       "11210  Using magazine, scrapbook paper, recycled old ...  \n",
       "\n",
       "[11128 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, foi verificado quantas categorias existem e qual a frequ√™ncia de cada categoria. Como √© poss√≠vel observar, a mais comum √© a de Viagem, enquanto a menos comum √© a de Hist√≥ria. Nesse caso, vamos mapear as classes aqui informadas para uma representa√ß√£o num√©rica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "travel blog           2200\n",
       "Science&Technology    2074\n",
       "Food                  1828\n",
       "manufacturing         1699\n",
       "Art&Music             1682\n",
       "History               1645\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Madagascar Street Food!!! Super RARE Malagasy ...</td>\n",
       "      <td>2</td>\n",
       "      <td>üé•GIANT ALIEN SNAIL IN JAPAN! ¬ª https://youtu.b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42 Foods You Need To Eat Before You Die</td>\n",
       "      <td>2</td>\n",
       "      <td>This is the ultimate must-try food bucket list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gordon Ramsay‚Äôs Top 5 Indian Dishes</td>\n",
       "      <td>2</td>\n",
       "      <td>We found 5 of the best and most interesting In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How To Use Chopsticks - In About A Minute üçú</td>\n",
       "      <td>2</td>\n",
       "      <td>You're most likely sitting in a restaurant wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying Indian Food 1st Time!</td>\n",
       "      <td>2</td>\n",
       "      <td>HELP SUPPORT SINSTV!! Shop Our Sponsors!\\nLast...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  Category  \\\n",
       "0  Madagascar Street Food!!! Super RARE Malagasy ...         2   \n",
       "1            42 Foods You Need To Eat Before You Die         2   \n",
       "2                Gordon Ramsay‚Äôs Top 5 Indian Dishes         2   \n",
       "3        How To Use Chopsticks - In About A Minute üçú         2   \n",
       "4                       Trying Indian Food 1st Time!         2   \n",
       "\n",
       "                                         Description  \n",
       "0  üé•GIANT ALIEN SNAIL IN JAPAN! ¬ª https://youtu.b...  \n",
       "1  This is the ultimate must-try food bucket list...  \n",
       "2  We found 5 of the best and most interesting In...  \n",
       "3  You're most likely sitting in a restaurant wit...  \n",
       "4  HELP SUPPORT SINSTV!! Shop Our Sponsors!\\nLast...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_categorias = df['Category'].value_counts().index.to_list()\n",
    "dict_mapeamento = dict()\n",
    "for i in range(len(lista_categorias)):\n",
    "    dict_mapeamento[lista_categorias[i]] = i\n",
    "df['Category'] = df['Category'].map(dict_mapeamento)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cria√ß√£o do Vetor TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O vetor TFIDF (Term Frequency - Inverse Document Frequency) √© baseado no modelo de Bag of Words e procura dar mais import√¢ncia para as palavras mais raras que aparecem dentro do corpo de um documento. Ainda assim, leva tamb√©m em considera√ß√£o as palavras mais frequentes. Ele foi escolhido em rela√ß√£o ao CountVectorizer, pois a acur√°cia dos modelos pareciam aumentar levemente quanto usando o TFIDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = df['Title'].apply(lambda x: x.lower()) # Tirando letras min√∫sculas\n",
    "df['Description'] = df['Description'].apply(lambda x: x.lower())\n",
    "df['Title'] = df['Title'].apply(lambda x: re.sub(\"[^a-zA-Z]\",\" \", x)) # Filtrando s√≠mbolos\n",
    "df['Description'] = df['Description'].apply(lambda x: re.sub(\"[^a-zA-Z]\",\" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://datascience.stackexchange.com/questions/25004/text-classifier-with-multiple-bag-of-words\n",
    "\n",
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "\n",
    "lista_stopwords = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "lista_frases = list()\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    lista_palavra = word_tokenize(row['Title'])\n",
    "    lista_palavra.extend(word_tokenize(row['Description']))\n",
    "    lista_string = []\n",
    "    for palavra in lista_palavra:\n",
    "        if palavra not in lista_stopwords:\n",
    "            palavra = ps.stem(palavra) # Stemming da palavra\n",
    "            lista_string.append(palavra)\n",
    "    string = \" \".join(lista_string)\n",
    "    lista_frases.append(string)\n",
    "\n",
    "array_frases = np.array(lista_frases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separa√ß√£o do Dataset entre Treinamento e Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link explicando melhor sobre Cross Validation: https://machinelearningmastery.com/training-validation-test-split-and-cross-validation-done-right/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11128, 77254)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(array_frases)\n",
    "print(X.shape)\n",
    "\n",
    "Y = df['Category'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, stratify=Y, test_size=0.33, shuffle=True)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10,  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fun√ß√£o para avaliar o modelo com Cross Validation e exibindo a acur√°cia e o f1 score (macro e weighted)\n",
    "def avalia_modelo(modelo):\n",
    "    scoring = [\"accuracy\", \"f1_macro\", \"f1_weighted\"]\n",
    "    scores = cross_validate(modelo, X, Y, cv=kfold, scoring=scoring, return_estimator=True)\n",
    "    print(\"Acur√°cia: %0.2f%%\" %(scores['test_accuracy'].mean()*100))\n",
    "    print(\"F1-Score Macro: %0.2f%%\" %(scores['test_f1_macro'].mean()*100))\n",
    "    print(\"F1-Score Weighted: %0.2f%%\" %(scores['test_f1_weighted'].mean()*100))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regress√£o Log√≠stica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regress√£o Log√≠stica:\n",
      "Acur√°cia: 96.52%\n",
      "F1-Score Macro: 96.56%\n",
      "F1-Score Weighted: 96.52%\n"
     ]
    }
   ],
   "source": [
    "# https://vitalflux.com/text-classification-bag-of-words-model-python-sklearn/\n",
    "# https://www.svm-tutorial.com/2014/10/svm-linear-kernel-good-text-classification/\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear') # Indicado para datasets menores\n",
    "print(\"Regress√£o Log√≠stica:\")\n",
    "avalia_modelo(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puc/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor score: 0.970884 | Par√¢metros = {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=lr, param_grid=grid, n_jobs=-1, cv=kfold, scoring='accuracy', error_score=0)\n",
    "grid_result = grid_search.fit(X, Y)\n",
    "print(\"Melhor score: %f | Par√¢metros = %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regress√£o Log√≠stica (Ap√≥s tuning de hiperpar√¢metros):\n",
      "Acur√°cia: 97.25%\n",
      "F1-Score Macro: 97.27%\n",
      "F1-Score Weighted: 97.25%\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='liblinear', C=10, penalty='l2')\n",
    "print(\"Regress√£o Log√≠stica (Ap√≥s tuning de hiperpar√¢metros):\")\n",
    "avalia_modelo(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradiente Descendente Estoc√°stico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD:\n",
      "Acur√°cia: 96.05%\n",
      "F1-Score Macro: 96.06%\n",
      "F1-Score Weighted: 96.05%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier, Perceptron\n",
    "\n",
    "sgd = SGDClassifier(loss='perceptron', learning_rate='optimal')\n",
    "print(\"SGD:\")\n",
    "avalia_modelo(sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron:\n",
      "Acur√°cia: 96.22%\n",
      "F1-Score Macro: 96.20%\n",
      "F1-Score Weighted: 96.22%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perc = Perceptron()\n",
    "print(\"Perceptron:\")\n",
    "avalia_modelo(perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √Årvore de Decis√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√Årvore de Decis√£o:\n",
      "Acur√°cia: 91.84%\n",
      "F1-Score Macro: 91.88%\n",
      "F1-Score Weighted: 91.84%\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "print(\"√Årvore de Decis√£o:\")\n",
    "avalia_modelo(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC (Supporting Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC:\n",
      "Acur√°cia: 96.26%\n",
      "F1-Score Macro: 96.28%\n",
      "F1-Score Weighted: 96.27%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "print(\"SVC:\")\n",
    "avalia_modelo(svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes:\n",
      "Acur√°cia: 88.16%\n",
      "F1-Score Macro: 88.20%\n",
      "F1-Score Weighted: 88.24%\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/16240721/sklearn-gaussiannb-bad-results-nan-probabilities porque nao √© bom com TF-IDF.\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "print(\"Multinomial Naive Bayes:\")\n",
    "avalia_modelo(nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Acur√°cia: 95.39%\n",
      "F1-Score Macro: 95.41%\n",
      "F1-Score Weighted: 95.39%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "print(\"Random Forest:\")\n",
    "avalia_modelo(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:\n",
      "Acur√°cia: 46.19%\n",
      "F1-Score Macro: 44.21%\n",
      "F1-Score Weighted: 44.67%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "print(\"KNN:\")\n",
    "avalia_modelo(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avalia√ß√£o da Regress√£o Log√≠stica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# def cross_val_predict(model, kfold, X, y):\n",
    "#     model_ = cp.deepcopy(model)\n",
    "#     no_classes = len(np.unique(y))\n",
    "#     actual_classes = np.empty([0], dtype=int)\n",
    "#     predicted_classes = np.empty([0], dtype=int)\n",
    "#     predicted_proba = np.empty([0, no_classes]) \n",
    "#     for train_ndx, test_ndx in kfold.split(X, y):\n",
    "#         train_X, train_y, test_X, test_y = X[train_ndx], y[train_ndx], X[test_ndx], y[test_ndx]\n",
    "#         actual_classes = np.append(actual_classes, test_y)\n",
    "#         model_.fit(train_X, train_y)\n",
    "#         predicted_classes = np.append(predicted_classes, model_.predict(test_X))\n",
    "#         try:\n",
    "#             predicted_proba = np.append(predicted_proba, model_.predict_proba(test_X), axis=0)\n",
    "#         except:\n",
    "#             predicted_proba = np.append(predicted_proba, np.zeros((len(test_X), no_classes), dtype=float), axis=0)\n",
    "\n",
    "#     return actual_classes, predicted_classes, predicted_proba\n",
    "\n",
    "\n",
    "# def plot_confusion_matrix(actual_classes, predicted_classes, sorted_labels):\n",
    "#     matrix = confusion_matrix(actual_classes, predicted_classes, labels=sorted_labels)\n",
    "#     plt.figure(figsize=(12.8,6))\n",
    "#     sns.heatmap(matrix, annot=True, xticklabels=sorted_labels, yticklabels=sorted_labels, cmap=\"Blues\", fmt=\"g\")\n",
    "#     plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')\n",
    "#     plt.show()\n",
    "\n",
    "# actual_classes, predicted_classes, _ = cross_val_predict(lr, kfold, X, Y)\n",
    "# plot_confusion_matrix(actual_classes, predicted_classes, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva de Aprendizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Regress√£o Log√≠stica\n",
    "tsize, training_score, test_score = learning_curve(lr, X, Y, cv=kfold, random_state=1000)\n",
    "\n",
    "avg_tr_scores = np.mean(training_score, axis=1)\n",
    "avg_test_scores = np.mean(test_score, axis=1)\n",
    "\n",
    "plt.plot(tsize,avg_tr_scores,label='Training Score')\n",
    "plt.plot(tsize,avg_test_scores,label='CV Score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confus√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que nesse caso a matriz de confus√£o abaixo n√£o √© feita em cima do Cross Validation utilizado para obter as m√©tricas do modelo. Para isso √© preciso ter uma nova fun√ß√£o de predi√ß√£o em cima do CV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "def matriz_confusao(modelo, X_train, X_test, y_train, y_test):\n",
    "    modelo.fit(X_train, y_train)\n",
    "    cm = confusion_matrix(y_test, modelo.predict(X_test))\n",
    "    plot_confusion_matrix(modelo, X_test, y_test, cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "\n",
    "matriz_confusao(lr, X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
