{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Classifica√ß√£o (Youtube Video Dataset)\n",
    "https://www.kaggle.com/datasets/rahulanand0070/youtubevideodataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# NLTK\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# SKLearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepara√ß√£o do Dataset\n",
    "\n",
    "A partir do .csv informado, vamos preparar o dataset para os algoritmos. Nesse caso, vamos remover valores nulos e filtrar as colunas de interesse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Videourl</th>\n",
       "      <th>Category</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Madagascar Street Food!!! Super RARE Malagasy ...</td>\n",
       "      <td>/watch?v=EwBA1fOQ96c</td>\n",
       "      <td>Food</td>\n",
       "      <td>üé•GIANT ALIEN SNAIL IN JAPAN! ¬ª https://youtu.b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42 Foods You Need To Eat Before You Die</td>\n",
       "      <td>/watch?v=0SPwwpruGIA</td>\n",
       "      <td>Food</td>\n",
       "      <td>This is the ultimate must-try food bucket list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gordon Ramsay‚Äôs Top 5 Indian Dishes</td>\n",
       "      <td>/watch?v=upfu5nQB2ks</td>\n",
       "      <td>Food</td>\n",
       "      <td>We found 5 of the best and most interesting In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How To Use Chopsticks - In About A Minute üçú</td>\n",
       "      <td>/watch?v=xFRzzSF_6gk</td>\n",
       "      <td>Food</td>\n",
       "      <td>You're most likely sitting in a restaurant wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying Indian Food 1st Time!</td>\n",
       "      <td>/watch?v=K79bXtaRwcM</td>\n",
       "      <td>Food</td>\n",
       "      <td>HELP SUPPORT SINSTV!! Shop Our Sponsors!\\r\\nLa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title              Videourl  \\\n",
       "0  Madagascar Street Food!!! Super RARE Malagasy ...  /watch?v=EwBA1fOQ96c   \n",
       "1            42 Foods You Need To Eat Before You Die  /watch?v=0SPwwpruGIA   \n",
       "2                Gordon Ramsay‚Äôs Top 5 Indian Dishes  /watch?v=upfu5nQB2ks   \n",
       "3        How To Use Chopsticks - In About A Minute üçú  /watch?v=xFRzzSF_6gk   \n",
       "4                       Trying Indian Food 1st Time!  /watch?v=K79bXtaRwcM   \n",
       "\n",
       "  Category                                        Description  \n",
       "0     Food  üé•GIANT ALIEN SNAIL IN JAPAN! ¬ª https://youtu.b...  \n",
       "1     Food  This is the ultimate must-try food bucket list...  \n",
       "2     Food  We found 5 of the best and most interesting In...  \n",
       "3     Food  You're most likely sitting in a restaurant wit...  \n",
       "4     Food  HELP SUPPORT SINSTV!! Shop Our Sponsors!\\r\\nLa...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/youtube_video_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas: Title Videourl Category Description\n",
      "N√∫mero de Linhas: 11211\n",
      "Colunas: Title Category Description\n",
      "N√∫mero de Linhas com Valores Nulos: 83\n",
      "N√∫mero de Linhas Ap√≥s Remo√ß√£o de Nulos: 11128\n",
      "N√∫mero de Linhas com Valores Nulos (Verifica√ß√£o): 0\n"
     ]
    }
   ],
   "source": [
    "colunas = list()\n",
    "for coluna in df.columns:\n",
    "    colunas.append(coluna)\n",
    "print(\"Colunas:\", \" \".join(colunas))\n",
    "print(\"N√∫mero de Linhas:\", df.shape[0])\n",
    "# Removendo as colunas que n√£o s√£o interessantes (nesse caso, apenas importa \"Title\" e \"Category\")\n",
    "df = df.iloc[:, [0, 2, 3]]\n",
    "colunas = list()\n",
    "for coluna in df.columns:\n",
    "    colunas.append(coluna)\n",
    "print(\"Colunas:\", \" \".join(colunas))\n",
    "print(\"N√∫mero de Linhas com Valores Nulos:\", df.isna().sum().sum())\n",
    "# Retirando linhas com valores nulos \n",
    "df = df.dropna()\n",
    "print(\"N√∫mero de Linhas Ap√≥s Remo√ß√£o de Nulos:\", df.shape[0])\n",
    "print(\"N√∫mero de Linhas com Valores Nulos (Verifica√ß√£o):\", df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novo dataset com as colunas novas e valores removidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Madagascar Street Food!!! Super RARE Malagasy ...</td>\n",
       "      <td>Food</td>\n",
       "      <td>üé•GIANT ALIEN SNAIL IN JAPAN! ¬ª https://youtu.b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42 Foods You Need To Eat Before You Die</td>\n",
       "      <td>Food</td>\n",
       "      <td>This is the ultimate must-try food bucket list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gordon Ramsay‚Äôs Top 5 Indian Dishes</td>\n",
       "      <td>Food</td>\n",
       "      <td>We found 5 of the best and most interesting In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How To Use Chopsticks - In About A Minute üçú</td>\n",
       "      <td>Food</td>\n",
       "      <td>You're most likely sitting in a restaurant wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying Indian Food 1st Time!</td>\n",
       "      <td>Food</td>\n",
       "      <td>HELP SUPPORT SINSTV!! Shop Our Sponsors!\\r\\nLa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11206</th>\n",
       "      <td>art journal | shimmer sprays, stencils, collag...</td>\n",
       "      <td>Art&amp;Music</td>\n",
       "      <td>Step by step video on creating an art journal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11207</th>\n",
       "      <td>Ar-Tea Collage * Mixed Media Art</td>\n",
       "      <td>Art&amp;Music</td>\n",
       "      <td>By: Ilene McInnes,\\r\\nMixed media Art and insp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11208</th>\n",
       "      <td>DIY Mixed Media Art Collage Greeting Cards / M...</td>\n",
       "      <td>Art&amp;Music</td>\n",
       "      <td>Make your own Mixed Media Greeting Cards\\r\\n\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11209</th>\n",
       "      <td>Art Collage Process DecoJournal using Rice Pap...</td>\n",
       "      <td>Art&amp;Music</td>\n",
       "      <td>Art Collage Process DecoJournal using Rice Pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11210</th>\n",
       "      <td>Journal Collage Process using Magazine Cut Out...</td>\n",
       "      <td>Art&amp;Music</td>\n",
       "      <td>Using magazine, scrapbook paper, recycled old ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11128 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title   Category  \\\n",
       "0      Madagascar Street Food!!! Super RARE Malagasy ...       Food   \n",
       "1                42 Foods You Need To Eat Before You Die       Food   \n",
       "2                    Gordon Ramsay‚Äôs Top 5 Indian Dishes       Food   \n",
       "3            How To Use Chopsticks - In About A Minute üçú       Food   \n",
       "4                           Trying Indian Food 1st Time!       Food   \n",
       "...                                                  ...        ...   \n",
       "11206  art journal | shimmer sprays, stencils, collag...  Art&Music   \n",
       "11207                   Ar-Tea Collage * Mixed Media Art  Art&Music   \n",
       "11208  DIY Mixed Media Art Collage Greeting Cards / M...  Art&Music   \n",
       "11209  Art Collage Process DecoJournal using Rice Pap...  Art&Music   \n",
       "11210  Journal Collage Process using Magazine Cut Out...  Art&Music   \n",
       "\n",
       "                                             Description  \n",
       "0      üé•GIANT ALIEN SNAIL IN JAPAN! ¬ª https://youtu.b...  \n",
       "1      This is the ultimate must-try food bucket list...  \n",
       "2      We found 5 of the best and most interesting In...  \n",
       "3      You're most likely sitting in a restaurant wit...  \n",
       "4      HELP SUPPORT SINSTV!! Shop Our Sponsors!\\r\\nLa...  \n",
       "...                                                  ...  \n",
       "11206  Step by step video on creating an art journal ...  \n",
       "11207  By: Ilene McInnes,\\r\\nMixed media Art and insp...  \n",
       "11208  Make your own Mixed Media Greeting Cards\\r\\n\\r...  \n",
       "11209  Art Collage Process DecoJournal using Rice Pap...  \n",
       "11210  Using magazine, scrapbook paper, recycled old ...  \n",
       "\n",
       "[11128 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, foi verificado quantas categorias existem e qual a frequ√™ncia de cada categoria. Como √© poss√≠vel observar, a mais comum √© a de Viagem, enquanto a menos comum √© a de Hist√≥ria. Nesse caso, vamos mapear as classes aqui informadas para uma representa√ß√£o num√©rica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "travel blog           2200\n",
       "Science&Technology    2074\n",
       "Food                  1828\n",
       "manufacturing         1699\n",
       "Art&Music             1682\n",
       "History               1645\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Madagascar Street Food!!! Super RARE Malagasy ...</td>\n",
       "      <td>2</td>\n",
       "      <td>üé•GIANT ALIEN SNAIL IN JAPAN! ¬ª https://youtu.b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42 Foods You Need To Eat Before You Die</td>\n",
       "      <td>2</td>\n",
       "      <td>This is the ultimate must-try food bucket list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gordon Ramsay‚Äôs Top 5 Indian Dishes</td>\n",
       "      <td>2</td>\n",
       "      <td>We found 5 of the best and most interesting In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How To Use Chopsticks - In About A Minute üçú</td>\n",
       "      <td>2</td>\n",
       "      <td>You're most likely sitting in a restaurant wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying Indian Food 1st Time!</td>\n",
       "      <td>2</td>\n",
       "      <td>HELP SUPPORT SINSTV!! Shop Our Sponsors!\\r\\nLa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  Category  \\\n",
       "0  Madagascar Street Food!!! Super RARE Malagasy ...         2   \n",
       "1            42 Foods You Need To Eat Before You Die         2   \n",
       "2                Gordon Ramsay‚Äôs Top 5 Indian Dishes         2   \n",
       "3        How To Use Chopsticks - In About A Minute üçú         2   \n",
       "4                       Trying Indian Food 1st Time!         2   \n",
       "\n",
       "                                         Description  \n",
       "0  üé•GIANT ALIEN SNAIL IN JAPAN! ¬ª https://youtu.b...  \n",
       "1  This is the ultimate must-try food bucket list...  \n",
       "2  We found 5 of the best and most interesting In...  \n",
       "3  You're most likely sitting in a restaurant wit...  \n",
       "4  HELP SUPPORT SINSTV!! Shop Our Sponsors!\\r\\nLa...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_categorias = df['Category'].value_counts().index.to_list()\n",
    "dict_mapeamento = dict()\n",
    "for i in range(len(lista_categorias)):\n",
    "    dict_mapeamento[lista_categorias[i]] = i\n",
    "df['Category'] = df['Category'].map(dict_mapeamento)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cria√ß√£o do Vetor TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Atualizar texto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langdetect'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [26], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#import nltk\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#nltk.download('punkt')\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#https://datascience.stackexchange.com/questions/25004/text-classifier-with-multiple-bag-of-words\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangdetect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m detect\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer, TfidfVectorizer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langdetect'"
     ]
    }
   ],
   "source": [
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "#https://datascience.stackexchange.com/questions/25004/text-classifier-with-multiple-bag-of-words\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer() # acur√°cia 93% com Tfid, 92% com CountVectorizer\n",
    "\n",
    "lista_stopwords = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "vocabulario = list()\n",
    "\n",
    "freq_idiomas = dict()\n",
    "\n",
    "df['Title'] = df['Title'].apply(lambda x: x.lower()) # Tirando letras min√∫sculas\n",
    "df['Title'] = df['Title'].apply(lambda x: re.sub(\"[^a-zA-Z]\",\" \", x)) # Filtrando s√≠mbolos\n",
    "\n",
    "lista_frases = list()\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    lista_palavra = word_tokenize(row['Title'])\n",
    "    lista_palavra.extend(word_tokenize(row['Description']))\n",
    "    lista_novo_titulo = []\n",
    "    for palavra in lista_palavra:\n",
    "        if palavra not in lista_stopwords:\n",
    "            palavra = ps.stem(palavra) # Stemming da palavra\n",
    "            vocabulario.append(palavra)\n",
    "            lista_novo_titulo.append(palavra)\n",
    "    string = \" \".join(lista_novo_titulo)\n",
    "    lista_frases.append(string)\n",
    "    df.at[i, 'Title'] = lista_novo_titulo\n",
    "\n",
    "array_frases = np.array(lista_frases)\n",
    "bag = vectorizer.fit_transform(array_frases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separa√ß√£o do Dataset entre Treinamento e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias = df['Category'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(bag, categorias, stratify=categorias, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regress√£o Log√≠stica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://vitalflux.com/text-classification-bag-of-words-model-python-sklearn/\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "lr = LogisticRegression(C=100.0, random_state=1, solver='lbfgs', multi_class='ovr')\n",
    "scores = cross_val_score(lr, bag, categorias, cv=10, scoring='accuracy')\n",
    "print(\"Acur√°cia da Regress√£o Log√≠stica: %0.2f%%\" % (scores.mean()*100)) ## talvez botar desvio padrao .std *2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confus√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://www.jcchouinard.com/confusion-matrix-in-scikit-learn/\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "# cm = confusion_matrix(y_test, y_test_predict)\n",
    "# plot_confusion_matrix(lr, x_test, y_test, cmap=plt.cm.Blues)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradiente Descendente Estoc√°stico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "sgd = SGDClassifier(loss='perceptron', learning_rate='optimal')\n",
    "scores = cross_val_score(sgd, bag, categorias, cv=10, scoring='accuracy')\n",
    "print(\"Acur√°cia do SGD: %0.2f%%\" % (scores.mean()*100))\n",
    "print(\"Desvio Padr√£o: \", scores.std()*2*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva de Aprendizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(estimator=lr, X=X_train, y=y_train, cv=10, train_sizes=np.linspace(0.1, 1.0, 10), n_jobs=1)\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training Accuracy')\n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, test_mean, color='green', marker='+', markersize=5, linestyle='--', label='Validation Accuracy')\n",
    "plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.ylabel('Model accuracy')\n",
    "plt.grid()\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
